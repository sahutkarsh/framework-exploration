{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_hyperlinks(query):\n",
    "    url = 'https://pubmed.ncbi.nlm.nih.gov/?term=' + '+'.join(query.split()) + '&filter=simsearch1.fha&size=100'\n",
    "    search_results = requests.get(url)\n",
    "    page_source = BeautifulSoup(search_results.content, 'html.parser')\n",
    "    papers = page_source.findAll('a', {'class': \"docsum-title\"})\n",
    "    hyperlinks = ['https://pubmed.ncbi.nlm.nih.gov' + paper['href'] for paper in papers]\n",
    "    return hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstract(url):\n",
    "    paper_page = requests.get(url)\n",
    "    page_source = BeautifulSoup(paper_page.content, 'html.parser')\n",
    "    title = page_source.find('h1', {'class': 'heading-title'}).text.strip()\n",
    "    abstract = page_source.find('div', {'id': 'enc-abstract'}).text.strip()\n",
    "    return [title, url, abstract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pages(query, n):\n",
    "    links = get_paper_hyperlinks(query)[:n]\n",
    "    abstracts = [get_abstract(link) for link in tqdm(links)]\n",
    "    scraped_data = pd.DataFrame(abstracts, columns=['Title', 'URL', 'Abstract'])\n",
    "    return scraped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape = False\n",
    "query = 'neurodegenerative diseases'\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scrape:\n",
    "    data = scrape_pages(query, n)\n",
    "    data.to_excel('abstracts.xlsx', index=False)\n",
    "else:\n",
    "    data = pd.read_excel('abstracts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurodegenerative disorders are characterized by progressive loss of selectively vulnerable populations of neurons, which contrasts with select static neuronal loss because of metabolic or toxic disorders. Neurodegenerative diseases can be classified according to primary clinical features (e.g., dementia, parkinsonism, or motor neuron disease), anatomic distribution of neurodegeneration (e.g., frontotemporal degenerations, extrapyramidal disorders, or spinocerebellar degenerations), or principal molecular abnormality. The most common neurodegenerative disorders are amyloidoses, tauopathies, Î±-synucleinopathies, and TDP-43 proteinopathies. The protein abnormalities in these disorders have abnormal conformational properties. Growing experimental evidence suggests that abnormal protein conformers may spread from cell to cell along anatomically connected pathways, which may in part explain the specific anatomical patterns observed at autopsy. In this review, we detail the human pathology of select neurodegenerative disorders, focusing on their main protein aggregates.\n",
      "\n",
      "Neurodegenerative diseases, the leading cause of morbidity and disability, are gaining increased attention as they impose a considerable socioeconomic impact, due in part to the ageing community. Neuronal damage is a pathological hallmark of Alzheimer's and Parkinson's diseases, amyotrophic lateral sclerosis, Huntington's disease, spinocerebellar ataxia and multiple sclerosis, although such damage is also observed following neurotropic viral infections, stroke, genetic white matter diseases and paraneoplastic disorders. Despite the different aetiologies, for example, infections, genetic mutations, trauma and protein aggregations, neuronal damage is frequently associated with chronic activation of an innate immune response in the CNS. The growing awareness that the immune system is inextricably involved in shaping the brain during development as well as mediating damage, but also regeneration and repair, has stimulated therapeutic approaches to modulate the immune system in neurodegenerative diseases. Here, we review the current understanding of how astrocytes and microglia, as well as neurons and oligodendrocytes, shape the neuroimmune response during development, and how aberrant responses that arise due to genetic or environmental triggers may predispose the CNS to neurodegenerative diseases. We discuss the known interactions between the peripheral immune system and the brain, and review the current concepts on how immune cells enter and leave the CNS. A better understanding of neuroimmune interactions during development and disease will be key to further manipulating these responses and the development of effective therapies to improve quality of life, and reduce the impact of neuroinflammatory and degenerative diseases.\n"
     ]
    }
   ],
   "source": [
    "print(data['Abstract'][0] + '\\n\\n' + data['Abstract'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    symbols = [',', '.', ':', '?', '/', ';', '[', ']', '(', ')', '&']\n",
    "    symbols_rep = [' ', ' ', ' ', ' ', ' ', ' ' , '', '', '', '', '']\n",
    "    for symbol, symbol_rep in zip(symbols, symbols_rep):\n",
    "        text = text.replace(symbol, symbol_rep)\n",
    "    text = ' '.join(text.split())\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(processed_data):\n",
    "    freq = {}\n",
    "    for text in processed_data:\n",
    "        for word in text.split():\n",
    "            if (word in freq):\n",
    "                freq[word] += 1\n",
    "            else:\n",
    "                freq[word] = 1\n",
    "    freq_df = pd.DataFrame.from_dict(freq, orient='index', columns=['Count'])\n",
    "    freq_df.sort_values(by='Count', ascending=False, inplace=True)\n",
    "    return [freq, freq_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = [process_text(text) for text in data['Abstract']]\n",
    "freq, freq_df = get_freq(processed_data)\n",
    "removed_words = list(freq_df[:10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = freq_df[10:]\n",
    "for removed_word in removed_words:\n",
    "    del freq[removed_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'and', 'in', 'diseases', 'neurodegenerative', 'to', 'a', 'disease', 'are']\n"
     ]
    }
   ],
   "source": [
    "print(removed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vector(text, freq, freq_df):\n",
    "    freq_abstract = dict.fromkeys(freq, 0)\n",
    "    for word in text.split():\n",
    "        if (word in freq):\n",
    "            freq_abstract[word] += 1\n",
    "    vector = []\n",
    "    for word in freq_df.index:\n",
    "        vector.append(freq_abstract[word])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(processed_data, freq, freq_df):\n",
    "    vectors = []\n",
    "    for text in processed_data:\n",
    "        vectors.append(compute_vector(text, freq, freq_df))\n",
    "    return np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_vectors(processed_data, freq, freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0] [1 4 2 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(vectors[0], vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering with Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(affinity='cosine', compute_full_tree='auto',\n",
       "                        connectivity=None, distance_threshold=None,\n",
       "                        linkage='complete', memory=None, n_clusters=6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AgglomerativeClustering(n_clusters=6, linkage='complete', affinity='cosine')\n",
    "model.fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5], dtype=int64),\n",
       " array([32, 24, 13, 11,  5, 15], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.Series(model.labels_)\n",
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Unique Words in Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though there could be many unique words in each cluster, we choose ones which have a frequency of 1 to ensure max uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = freq_df.reset_index()\n",
    "unique_words = unique_words[unique_words['Count'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_cluster = []\n",
    "for label_index in range(6):\n",
    "    vectors_cluster.append(vectors[labels == label_index].sum(axis=0))\n",
    "vectors_cluster = np.array(vectors_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_one_hot = np.transpose(vectors_cluster[:, unique_words.index])\n",
    "unique_cluster_labels = []\n",
    "for one_hot in unique_one_hot:\n",
    "    unique_cluster_labels.append(np.where(one_hot == 1)[0][0])\n",
    "unique_words['Cluster'] = unique_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    483\n",
       "1    324\n",
       "2    248\n",
       "5    209\n",
       "3    107\n",
       "4     60\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Words\n",
      "Cluster 0: advantageous, administration, designing\n",
      "Cluster 1: redundant, accidental, reputed\n",
      "Cluster 2: converge, autoinflammatory, contrary\n",
      "Cluster 3: begins, opinion, displays\n",
      "Cluster 4: whereas, examination, accompany\n",
      "Cluster 5: world, amyloid-Ã, class\n"
     ]
    }
   ],
   "source": [
    "print('Unique Words')\n",
    "for label_index in range(6):\n",
    "    top_unique_words = list(unique_words[unique_words['Cluster'] == label_index]['index'])\n",
    "    print('Cluster ' + str(label_index) + ': ' + ', '.join(top_unique_words[-3:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
